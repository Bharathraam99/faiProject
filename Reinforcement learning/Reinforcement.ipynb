{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/supre/Documents/FAI/PROJECT /Users/fletcher/.cache/kagglehub/datasets/prodzar/stocks-historical-price-data/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"prodzar/stocks-historical-price-data\")\n",
    "\n",
    "print(\"C:/Users/supre/Documents/FAI/PROJECT\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data merged successfully into merged_stocks_data.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to your directory containing the CSV files\n",
    "current_dir = os.getcwd()\n",
    "download_path = os.path.join(current_dir, '..', 'dataset', 'historical_data')\n",
    "download_path = os.path.normpath(download_path)\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for file in os.listdir(download_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        # Extract company name from the filename (without .csv extension)\n",
    "        company_name = file.replace(\".csv\", \"\")\n",
    "        \n",
    "        # Load CSV into a DataFrame\n",
    "        file_path = os.path.join(download_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Add a new column for the company name\n",
    "        df[\"Company\"] = company_name\n",
    "        \n",
    "        # Append to the merged DataFrame\n",
    "        merged_data = pd.concat([merged_data, df], ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "output_path = os.path.join(current_dir, '..', 'merged_stocks_data.csv')\n",
    "output_path = os.path.normpath(output_path)\n",
    "merged_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Data merged successfully into merged_stocks_data.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>271.279999</td>\n",
       "      <td>272.910004</td>\n",
       "      <td>268.750000</td>\n",
       "      <td>270.899994</td>\n",
       "      <td>2526600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>270.510010</td>\n",
       "      <td>272.809998</td>\n",
       "      <td>257.529999</td>\n",
       "      <td>259.029999</td>\n",
       "      <td>3903400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>263.269989</td>\n",
       "      <td>268.929993</td>\n",
       "      <td>257.459991</td>\n",
       "      <td>268.709991</td>\n",
       "      <td>3750800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>272.779999</td>\n",
       "      <td>273.209991</td>\n",
       "      <td>268.390015</td>\n",
       "      <td>272.859985</td>\n",
       "      <td>2650400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>273.720001</td>\n",
       "      <td>275.760010</td>\n",
       "      <td>271.049988</td>\n",
       "      <td>274.799988</td>\n",
       "      <td>2211800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADBE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Volume  \\\n",
       "0  2019-05-31  271.279999  272.910004  268.750000  270.899994  2526600   \n",
       "1  2019-06-03  270.510010  272.809998  257.529999  259.029999  3903400   \n",
       "2  2019-06-04  263.269989  268.929993  257.459991  268.709991  3750800   \n",
       "3  2019-06-05  272.779999  273.209991  268.390015  272.859985  2650400   \n",
       "4  2019-06-06  273.720001  275.760010  271.049988  274.799988  2211800   \n",
       "\n",
       "   Dividends  Stock Splits Company  \n",
       "0        0.0           0.0    ADBE  \n",
       "1        0.0           0.0    ADBE  \n",
       "2        0.0           0.0    ADBE  \n",
       "3        0.0           0.0    ADBE  \n",
       "4        0.0           0.0    ADBE  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import ta\n",
    "from collections import deque\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1, Total Reward: -2435.58, Balance: 7564.42, Shares Held: 0\n",
      "Episode 2, Total Reward: -2246.00, Balance: 7754.00, Shares Held: 0\n",
      "Episode 3, Total Reward: -2589.92, Balance: 7410.08, Shares Held: 0\n",
      "Episode 4, Total Reward: -2423.31, Balance: 7576.69, Shares Held: 0\n",
      "Episode 5, Total Reward: -2289.14, Balance: 7710.86, Shares Held: 0\n",
      "Episode 6, Total Reward: -2304.37, Balance: 7695.63, Shares Held: 0\n",
      "Episode 7, Total Reward: -2356.07, Balance: 7643.93, Shares Held: 0\n",
      "Episode 8, Total Reward: -2329.57, Balance: 7670.43, Shares Held: 0\n",
      "Episode 9, Total Reward: -2047.32, Balance: 7952.68, Shares Held: 0\n",
      "Episode 10, Total Reward: -2487.13, Balance: 7512.87, Shares Held: 0\n",
      "Episode 11, Total Reward: -2427.03, Balance: 7572.97, Shares Held: 0\n",
      "Episode 12, Total Reward: -2359.90, Balance: 7640.10, Shares Held: 0\n",
      "Episode 13, Total Reward: -2326.33, Balance: 7673.67, Shares Held: 0\n",
      "Episode 14, Total Reward: -2317.76, Balance: 7682.24, Shares Held: 0\n",
      "Episode 15, Total Reward: -2115.85, Balance: 7884.15, Shares Held: 0\n",
      "Episode 16, Total Reward: -2567.02, Balance: 7432.98, Shares Held: 0\n",
      "Episode 17, Total Reward: -2066.53, Balance: 7933.47, Shares Held: 0\n",
      "Episode 18, Total Reward: -2041.07, Balance: 7958.93, Shares Held: 0\n",
      "Episode 19, Total Reward: -1919.19, Balance: 8080.81, Shares Held: 0\n",
      "Episode 20, Total Reward: -1988.12, Balance: 8011.88, Shares Held: 0\n",
      "Episode 21, Total Reward: -1968.33, Balance: 8031.67, Shares Held: 0\n",
      "Episode 22, Total Reward: -2044.31, Balance: 7955.69, Shares Held: 0\n",
      "Episode 23, Total Reward: -2124.55, Balance: 7875.45, Shares Held: 0\n",
      "Episode 24, Total Reward: -2303.92, Balance: 7696.08, Shares Held: 0\n",
      "Episode 25, Total Reward: -2088.91, Balance: 7911.09, Shares Held: 0\n",
      "Episode 26, Total Reward: -2161.98, Balance: 7838.02, Shares Held: 0\n",
      "Episode 27, Total Reward: -2036.62, Balance: 7963.38, Shares Held: 0\n",
      "Episode 28, Total Reward: -2287.66, Balance: 7712.34, Shares Held: 0\n",
      "Episode 29, Total Reward: -2011.59, Balance: 7988.41, Shares Held: 0\n",
      "Episode 30, Total Reward: -2189.57, Balance: 7810.43, Shares Held: 0\n",
      "Episode 31, Total Reward: -2004.41, Balance: 7995.59, Shares Held: 0\n",
      "Episode 32, Total Reward: -2025.65, Balance: 7974.35, Shares Held: 0\n",
      "Episode 33, Total Reward: -2087.32, Balance: 7912.68, Shares Held: 0\n",
      "Episode 34, Total Reward: -1877.42, Balance: 8122.58, Shares Held: 0\n",
      "Episode 35, Total Reward: -2086.09, Balance: 7913.91, Shares Held: 0\n",
      "Episode 36, Total Reward: -2257.41, Balance: 7742.59, Shares Held: 0\n",
      "Episode 37, Total Reward: -1988.54, Balance: 8011.46, Shares Held: 0\n",
      "Episode 38, Total Reward: -1915.66, Balance: 8084.34, Shares Held: 0\n",
      "Episode 39, Total Reward: -1995.84, Balance: 8004.16, Shares Held: 0\n",
      "Episode 40, Total Reward: -2117.41, Balance: 7882.59, Shares Held: 0\n",
      "Episode 41, Total Reward: -2188.76, Balance: 7811.24, Shares Held: 0\n",
      "Episode 42, Total Reward: -1963.82, Balance: 8036.18, Shares Held: 0\n",
      "Episode 43, Total Reward: -2009.66, Balance: 7990.34, Shares Held: 0\n",
      "Episode 44, Total Reward: -1838.59, Balance: 8161.41, Shares Held: 0\n",
      "Episode 45, Total Reward: -1977.84, Balance: 8022.16, Shares Held: 0\n",
      "Episode 46, Total Reward: -2087.21, Balance: 7912.79, Shares Held: 0\n",
      "Episode 47, Total Reward: -1817.16, Balance: 8182.84, Shares Held: 0\n",
      "Episode 48, Total Reward: -1895.33, Balance: 8104.67, Shares Held: 0\n",
      "Episode 49, Total Reward: -1796.68, Balance: 8203.32, Shares Held: 0\n",
      "Episode 50, Total Reward: -1935.84, Balance: 8064.16, Shares Held: 0\n",
      "Episode 51, Total Reward: -1873.13, Balance: 8126.87, Shares Held: 0\n",
      "Episode 52, Total Reward: -1628.72, Balance: 8371.28, Shares Held: 0\n",
      "Episode 53, Total Reward: -1658.18, Balance: 8341.82, Shares Held: 0\n",
      "Episode 54, Total Reward: -1875.68, Balance: 8124.32, Shares Held: 0\n",
      "Episode 55, Total Reward: -1854.36, Balance: 8145.64, Shares Held: 0\n",
      "Episode 56, Total Reward: -1658.24, Balance: 8341.76, Shares Held: 0\n",
      "Episode 57, Total Reward: -1939.90, Balance: 8060.10, Shares Held: 0\n",
      "Episode 58, Total Reward: -1753.48, Balance: 8246.52, Shares Held: 0\n",
      "Episode 59, Total Reward: -1826.78, Balance: 8173.22, Shares Held: 0\n",
      "Episode 60, Total Reward: -1646.73, Balance: 8353.27, Shares Held: 0\n",
      "Episode 61, Total Reward: -1679.55, Balance: 8320.45, Shares Held: 0\n",
      "Episode 62, Total Reward: -1607.73, Balance: 8392.27, Shares Held: 0\n",
      "Episode 63, Total Reward: -1781.92, Balance: 8218.08, Shares Held: 0\n",
      "Episode 64, Total Reward: -1559.02, Balance: 8440.98, Shares Held: 0\n",
      "Episode 65, Total Reward: -1838.46, Balance: 8161.54, Shares Held: 0\n",
      "Episode 66, Total Reward: -1804.23, Balance: 8195.77, Shares Held: 0\n",
      "Episode 67, Total Reward: -1758.46, Balance: 8241.54, Shares Held: 0\n",
      "Episode 68, Total Reward: -1819.32, Balance: 8180.68, Shares Held: 0\n",
      "Episode 69, Total Reward: -1707.11, Balance: 8292.89, Shares Held: 0\n",
      "Episode 70, Total Reward: -1876.06, Balance: 8123.94, Shares Held: 0\n",
      "Episode 71, Total Reward: -1555.42, Balance: 8444.58, Shares Held: 0\n",
      "Episode 72, Total Reward: -1630.88, Balance: 8369.12, Shares Held: 0\n",
      "Episode 73, Total Reward: -1618.21, Balance: 8381.79, Shares Held: 0\n",
      "Episode 74, Total Reward: -1855.45, Balance: 8144.55, Shares Held: 0\n",
      "Episode 75, Total Reward: -1638.84, Balance: 8361.16, Shares Held: 0\n",
      "Episode 76, Total Reward: -1425.09, Balance: 8574.91, Shares Held: 0\n",
      "Episode 77, Total Reward: -1507.23, Balance: 8492.77, Shares Held: 0\n",
      "Episode 78, Total Reward: -1498.94, Balance: 8501.06, Shares Held: 0\n",
      "Episode 79, Total Reward: -1785.34, Balance: 8214.66, Shares Held: 0\n",
      "Episode 80, Total Reward: -1657.16, Balance: 8342.84, Shares Held: 0\n",
      "Episode 81, Total Reward: -1507.86, Balance: 8492.14, Shares Held: 0\n",
      "Episode 82, Total Reward: -1543.46, Balance: 8456.54, Shares Held: 0\n",
      "Episode 83, Total Reward: -1435.61, Balance: 8564.39, Shares Held: 0\n",
      "Episode 84, Total Reward: -1716.22, Balance: 8283.78, Shares Held: 0\n",
      "Episode 85, Total Reward: -1679.09, Balance: 8320.91, Shares Held: 0\n",
      "Episode 86, Total Reward: -1456.30, Balance: 8543.70, Shares Held: 0\n",
      "Episode 87, Total Reward: -1357.28, Balance: 8642.72, Shares Held: 0\n",
      "Episode 88, Total Reward: -1746.14, Balance: 8253.86, Shares Held: 0\n",
      "Episode 89, Total Reward: -1437.39, Balance: 8562.61, Shares Held: 0\n",
      "Episode 90, Total Reward: -1365.75, Balance: 8634.25, Shares Held: 0\n",
      "Episode 91, Total Reward: -1537.22, Balance: 8462.78, Shares Held: 0\n",
      "Episode 92, Total Reward: -1465.70, Balance: 8534.30, Shares Held: 0\n",
      "Episode 93, Total Reward: -1489.46, Balance: 8510.54, Shares Held: 0\n",
      "Episode 94, Total Reward: -1620.18, Balance: 8379.82, Shares Held: 0\n",
      "Episode 95, Total Reward: -1543.77, Balance: 8456.23, Shares Held: 0\n",
      "Episode 96, Total Reward: -1596.39, Balance: 8403.61, Shares Held: 0\n",
      "Episode 97, Total Reward: -1264.96, Balance: 8735.04, Shares Held: 0\n",
      "Episode 98, Total Reward: -1396.78, Balance: 8603.22, Shares Held: 0\n",
      "Episode 99, Total Reward: -1575.60, Balance: 8424.40, Shares Held: 0\n",
      "Episode 100, Total Reward: -1636.21, Balance: 8363.79, Shares Held: 0\n",
      "Training complete.\n",
      "Test Total Reward: 0.00, Final Balance: 10000.00, Shares Held: 0\n"
     ]
    }
   ],
   "source": [
    "# Function to compute RSI using the ta library\n",
    "def compute_rsi(series, window=14):\n",
    "    return ta.momentum.RSIIndicator(series, window=window).rsi()\n",
    "\n",
    "# Define the base directory (adjust based on your project structure)\n",
    "base_dir = Path.cwd().parent  # Assuming the notebook is inside 'Reinforcement learning' folder\n",
    "\n",
    "# Define the relative path to the merged_stocks_data.csv\n",
    "data_path = base_dir / 'merged_stocks_data.csv'\n",
    "\n",
    "# Check if the file exists\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f\"The file {data_path} does not exist.\")\n",
    "\n",
    "# Load your merged data using the relative path\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Filter data by company name (e.g., for a specific company)\n",
    "company_data = data[data['Company'] == 'AAPL'].reset_index(drop=True)\n",
    "\n",
    "# Feature Engineering: Adding Moving Averages as technical indicators\n",
    "company_data['MA10'] = company_data['Close'].rolling(window=10).mean()\n",
    "company_data['MA50'] = company_data['Close'].rolling(window=50).mean()\n",
    "company_data['RSI'] = compute_rsi(company_data['Close'], window=14)  # Using ta library\n",
    "\n",
    "# Drop rows with NaN values resulting from moving averages and RSI, then reset the index\n",
    "company_data = company_data.dropna().reset_index(drop=True)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "company_data[['Open', 'High', 'Low', 'Close', 'Volume', 'MA10', 'MA50', 'RSI']] = scaler.fit_transform(\n",
    "    company_data[['Open', 'High', 'Low', 'Close', 'Volume', 'MA10', 'MA50', 'RSI']]\n",
    ")\n",
    "\n",
    "# Q-learning parameters\n",
    "actions = [\"Buy\", \"Sell\", \"Hold\"]  # Actions the agent can take\n",
    "alpha = 0.1  # Learning rate\n",
    "gamma = 0.95  # Discount factor\n",
    "epsilon = 1.0  # Exploration rate\n",
    "epsilon_decay = 0.995  # Decay rate for epsilon\n",
    "q_table = {}  # Q-table for state-action pairs\n",
    "\n",
    "# Initialize environment parameters\n",
    "initial_balance = 10000  # Increased initial balance for multiple shares\n",
    "balance = initial_balance  # Current balance\n",
    "shares_held = 0  # Initial shares held\n",
    "transaction_cost = 10  # Fixed transaction cost per trade\n",
    "\n",
    "# Function to get state\n",
    "def get_state(data, t):\n",
    "    return tuple(data.iloc[t][[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"MA10\", \"MA50\", \"RSI\"]])\n",
    "\n",
    "# Reward function: calculates net profit/loss for an action\n",
    "def get_reward(action, current_price, shares_held, balance, prev_balance):\n",
    "    if action == \"Sell\" and shares_held > 0:\n",
    "        profit = shares_held * current_price - transaction_cost\n",
    "        return profit\n",
    "    elif action == \"Buy\" and balance >= (current_price + transaction_cost):\n",
    "        cost = current_price + transaction_cost\n",
    "        return -cost\n",
    "    else:\n",
    "        return 0  # \"Hold\" or not enough balance\n",
    "\n",
    "# Q-learning algorithm\n",
    "for episode in range(1, 101):  # Training for 100 episodes\n",
    "    balance = initial_balance\n",
    "    shares_held = 0\n",
    "    total_reward = 0\n",
    "    \n",
    "    for t in range(len(company_data) - 1):\n",
    "        state = get_state(company_data, t)\n",
    "        \n",
    "        # Initialize Q-values for unseen states\n",
    "        if state not in q_table:\n",
    "            q_table[state] = [0] * len(actions)\n",
    "        \n",
    "        # Epsilon-greedy action selection\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action_index = random.randint(0, len(actions) - 1)  # Explore\n",
    "        else:\n",
    "            action_index = np.argmax(q_table[state])  # Exploit\n",
    "        \n",
    "        action = actions[action_index]\n",
    "        current_price = company_data.loc[t, \"Close\"]\n",
    "        prev_balance = balance\n",
    "        reward = get_reward(action, current_price, shares_held, balance, balance)\n",
    "        \n",
    "        # Update balance and shares held based on action\n",
    "        if action == \"Buy\" and balance >= (current_price + transaction_cost):\n",
    "            balance -= (current_price + transaction_cost)\n",
    "            shares_held += 1\n",
    "        elif action == \"Sell\" and shares_held > 0:\n",
    "            balance += (shares_held * current_price - transaction_cost)\n",
    "            shares_held = 0\n",
    "        \n",
    "        total_reward += reward\n",
    "        \n",
    "        # Next state\n",
    "        next_state = get_state(company_data, t + 1)\n",
    "        \n",
    "        # Initialize Q-values for unseen next states\n",
    "        if next_state not in q_table:\n",
    "            q_table[next_state] = [0] * len(actions)\n",
    "        \n",
    "        # Q-learning update using Bellman equation\n",
    "        old_q_value = q_table[state][action_index]\n",
    "        next_max_q = max(q_table[next_state])\n",
    "        q_table[state][action_index] = old_q_value + alpha * (reward + gamma * next_max_q - old_q_value)\n",
    "    \n",
    "    # Handle end-of-episode: sell any remaining shares\n",
    "    if shares_held > 0:\n",
    "        final_price = company_data.loc[len(company_data) - 1, \"Close\"]\n",
    "        balance += (shares_held * final_price - transaction_cost)\n",
    "        total_reward += (shares_held * final_price - transaction_cost)\n",
    "        shares_held = 0\n",
    "    \n",
    "    # Decay epsilon\n",
    "    epsilon = max(epsilon * epsilon_decay, 0.01)\n",
    "    \n",
    "    # Logging\n",
    "    print(f\"Episode {episode}, Total Reward: {total_reward:.2f}, Balance: {balance:.2f}, Shares Held: {shares_held}\")\n",
    "    \n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Test phase (using the trained Q-table)\n",
    "balance = initial_balance\n",
    "shares_held = 0\n",
    "total_reward = 0\n",
    "\n",
    "for t in range(len(company_data) - 1):\n",
    "    state = get_state(company_data, t)\n",
    "    if state not in q_table:\n",
    "        q_table[state] = [0] * len(actions)\n",
    "    \n",
    "    action_index = np.argmax(q_table[state])  # Always exploit\n",
    "    action = actions[action_index]\n",
    "    current_price = company_data.loc[t, \"Close\"]\n",
    "    \n",
    "    # Apply action\n",
    "    if action == \"Buy\" and balance >= (current_price + transaction_cost):\n",
    "        balance -= (current_price + transaction_cost)\n",
    "        shares_held += 1\n",
    "        reward = - (current_price + transaction_cost)\n",
    "    elif action == \"Sell\" and shares_held > 0:\n",
    "        balance += (shares_held * current_price - transaction_cost)\n",
    "        reward = (shares_held * current_price - transaction_cost)\n",
    "        shares_held = 0\n",
    "    else:\n",
    "        reward = 0  # Hold\n",
    "    \n",
    "    total_reward += reward\n",
    "\n",
    "# Sell any remaining shares at the end of the test\n",
    "if shares_held > 0:\n",
    "    final_price = company_data.loc[len(company_data) - 1, \"Close\"]\n",
    "    balance += (shares_held * final_price - transaction_cost)\n",
    "    total_reward += (shares_held * final_price - transaction_cost)\n",
    "    shares_held = 0\n",
    "\n",
    "print(f\"Test Total Reward: {total_reward:.2f}, Final Balance: {balance:.2f}, Shares Held: {shares_held}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State and Q-Table: For each day in the test data, the agent retrieves the current state and checks for that state in the Q-table.\n",
    "\n",
    "Exploitation (No Exploration): For each state in the test data, the agent selects the action with the highest Q-value.\n",
    "\n",
    "Action Execution:\n",
    "\"Buy\": Deduct the price of one stock from the balance and increase the shares_held.\n",
    "\"Sell\": Add the value of all held shares to the balance and set shares_held to zero.\n",
    "\n",
    "Portfolio Value Calculation: Tracks the total portfolio value (balance + value of held shares) to see the agent’s progress.\n",
    "\n",
    "End of Testing: Prints the final portfolio value and total profit at the end of the test period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
